import streamlit as st
import pandas as pd
from openai import OpenAI
import json
from datetime import datetime
import re
from io import BytesIO
import time

st.set_page_config(
    page_title="AnÃ¡lise de Risco de ExternalizaÃ§Ã£o - Base ManifestaÃ§Ãµes",
    page_icon="âš ï¸",
    layout="wide"
)

# Configurar OpenAI API usando secrets do Streamlit
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error("âš ï¸ Erro ao configurar OpenAI API. Verifique se a chave estÃ¡ configurada em Settings > Secrets do Streamlit.")
    st.stop()

def classify_channel_type(channel_value):
    """
    Classifica o canal como Interno ou Externo
    
    Pesos dos canais externos:
    - Ext. Ouvidoria: 100 pontos
    - Externo / Web - Reclame Aqui: 75 pontos
    - Externo - Focais: 50 pontos
    """
    if pd.isna(channel_value):
        return "Interno", 0
    
    channel_str = str(channel_value).strip().lower()
    
    # Externos
    if "ouvidoria" in channel_str:
        return "Externo", 100
    elif "reclame aqui" in channel_str or "reclameaqui" in channel_str:
        return "Externo", 75
    elif "focais" in channel_str or "externo - focais" in channel_str:
        return "Externo", 50
    elif "externo" in channel_str:
        return "Externo", 75
    
    # Internos
    else:
        return "Interno", 0

def analyze_internal_risk(client, text, nr_ocorrencia="N/A"):
    """
    EIXO 1: AnÃ¡lise de risco de reclamaÃ§Ãµes INTERNAS virarem EXTERNAS (0-100 pontos)
    
    Usa a metodologia completa do cÃ³digo original SRO
    """
    
    prompt = f"""VocÃª Ã© um analista preditivo especializado em prever o risco de reclamaÃ§Ãµes internas se tornarem externas.

CONTEXTO:
Esta Ã© uma reclamaÃ§Ã£o INTERNA (NR_OCORRENCIA: {nr_ocorrencia})

TEXTO DA RECLAMAÃ‡ÃƒO:
{text}

TAREFA:
Analise o texto e calcule o risco (0-100 pontos) de esta reclamaÃ§Ã£o INTERNA se tornar EXTERNA (ReclameAqui, Procon, Ouvidoria).

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
METODOLOGIA DE ANÃLISE (EIXO 1 - INTERNALIZAÃ‡ÃƒO â†’ EXTERNALIZAÃ‡ÃƒO)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Fatores Preditivos e Pesos:

1. FREQUÃŠNCIA DE CONTATOS â€“ Peso 4 (mÃ¡ximo 40 pontos)
   - 1 contato: 0 pts (risco baixo)
   - 2 contatos: 5 pts (risco mÃ©dio)
   - 3+ contatos: 10 pts (risco elevado)
   
   AtenuaÃ§Ã£o: Se mÃºltiplos contatos contÃªm palavras neutras de acompanhamento, reduzir pontos.
   
   Palavras neutras: fila, data, equipe, atualizaÃ§Ã£o, agenda, recontato, inserido, tabela, negociado, complemento, evento, telefone, inicial, observaÃ§Ã£o, pergunta, item, escala, criaÃ§Ã£o, responsÃ¡vel, cancelado, negativa, tÃ©cnica, cobertura, atendimento

2. TEMPO DE ESPERA / ATRASOS â€“ Peso 3 (mÃ¡ximo 30 pontos)
   - MenÃ§Ã£o a atrasos: +10 pts
   - MenÃ§Ã£o a "dias", "semanas" de espera: +10 pts
   - MenÃ§Ã£o a prazos nÃ£o cumpridos: +10 pts

3. FALHAS OPERACIONAIS â€“ Peso 2 (mÃ¡ximo 20 pontos)
   
   A. IndÃ­cios tÃ©cnicos graves (10 pts cada):
      - defeito, conserto, danos, sinistro, vazamento, barulho, quebra
      - arranhado, sujo, manchado, escorrida, descolado, solto
      - acendendo, parou, sumiu, faltando, faltou, errado, errada
      - incompleto, danificado, estragado, pior, voltou
      - torto, amassado, mal feito, falta de cuidado
   
   B. Falhas de processo (5 pts cada):
      - cadastro incorreto, solicitaÃ§Ãµes nÃ£o atendidas
      - falhas de comunicaÃ§Ã£o, problemas tÃ©cnicos pÃ³s-serviÃ§o
      - cada atendente dÃ¡ informaÃ§Ã£o diferente

4. ESTADO EMOCIONAL â€“ Peso 1 (mÃ¡ximo 10 pontos)
   
   Termos negativos moderados (1 pt cada):
   - terrÃ­vel, pÃ©ssimo, horrÃ­vel, decepcionado, frustrado
   - reclamar, problema, erro, falha, demora, demorado
   - insatisfeito, revoltado, indignado, absurdo, inaceitÃ¡vel
   
   Termos de risco jurÃ­dico (3 pts cada):
   - processar, advogado, jurÃ­dico, procon, denÃºncia
   - Ã³rgÃ£o, fiscalizaÃ§Ã£o, consumidor, direito, prejuÃ­zo
   
   Termos positivos (reduzem -1 pt cada):
   - excelente, Ã³timo, perfeito, maravilhoso, fantÃ¡stico
   - agradecer, obrigado, parabÃ©ns, satisfeito, contente
   - recomendo, eficiente, rÃ¡pido, atencioso, prestativo

REGRA ESPECIAL - Negativas TÃ©cnicas:
Se o texto contÃ©m apenas negativa tÃ©cnica/cancelamento SEM insatisfaÃ§Ã£o explÃ­cita do cliente:
â†’ Score mÃ¡ximo = 30 pontos (Baixo)

Para elevar acima de 30, deve haver:
- ManifestaÃ§Ã£o direta de descontentamento
- Termos emocionais negativos do cliente
- Questionamento da decisÃ£o tÃ©cnica
- AmeaÃ§as ou menÃ§Ãµes a Ã³rgÃ£os externos
- MÃºltiplos contatos com tom de cobranÃ§a

CÃLCULO FINAL:
1. Atribua score (0-10) para cada fator
2. Multiplique pelo peso do fator
3. Some os valores ponderados (mÃ¡ximo 100)
4. Aplique regra especial se for negativa tÃ©cnica
5. Classifique:
   - Baixo: 0-30 pontos
   - MÃ©dio: 31-60 pontos
   - Alto: 61-85 pontos
   - CrÃ­tico: 86-100 pontos

FORMATO DE SAÃDA (JSON):
{{
    "risk_score": <nÃºmero de 0 a 100>,
    "risk_level": "<Baixo/MÃ©dio/Alto/CrÃ­tico>",
    "frequency_score": <0-40>,
    "delay_score": <0-30>,
    "operational_score": <0-20>,
    "emotional_score": <0-10>,
    "key_factors": ["fator1", "fator2", "fator3"],
    "detected_threats": ["ameaÃ§a1", "ameaÃ§a2"],
    "emotional_tone": "<descriÃ§Ã£o do tom emocional>",
    "is_technical_negative": <true/false>,
    "recommendation": "<recomendaÃ§Ã£o de aÃ§Ã£o>"
}}

Retorne APENAS o JSON, sem texto adicional."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "VocÃª Ã© um analista preditivo especializado em prever externalizaÃ§Ãµes de reclamaÃ§Ãµes usando metodologia ponderada."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1000
        )
        
        result_text = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        
        if json_match:
            return json.loads(json_match.group())
        else:
            return create_error_result("Erro ao processar resposta da IA")
            
    except Exception as e:
        return create_error_result(str(e))

def analyze_external_risk(client, text, nr_ocorrencia="N/A", channel_base_score=50):
    """
    EIXO 2: AnÃ¡lise de risco de reclamaÃ§Ãµes EXTERNAS serem ESCALADAS/REPETIDAS (100-1000 pontos)
    
    Usa a metodologia completa do cÃ³digo original SRO para externalizaÃ§Ã£o
    Base: 100-1000 pontos (10x a escala original para dar mais granularidade)
    """
    
    prompt = f"""VocÃª Ã© um analista preditivo especializado em prever escalaÃ§Ã£o e reincidÃªncia de reclamaÃ§Ãµes externas.

CONTEXTO:
Esta Ã© uma reclamaÃ§Ã£o EXTERNA (NR_OCORRENCIA: {nr_ocorrencia})
Peso base do canal: {channel_base_score} pontos

TEXTO DA RECLAMAÃ‡ÃƒO:
{text}

TAREFA:
Analise o texto e calcule o risco (0-1000 pontos) de o cliente ESCALAR ou RECLAMAR NOVAMENTE.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
METODOLOGIA DE ANÃLISE (EIXO 2 - EXTERNALIZAÃ‡ÃƒO E ESCALAÃ‡ÃƒO)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Fatores de ExternalizaÃ§Ã£o e EscalaÃ§Ã£o:

1. INDICADORES TEXTUAIS DE EXTERNALIZAÃ‡ÃƒO â€“ Peso 5 (mÃ¡ximo 500 pontos)

   A. MenÃ§Ãµes ExplÃ­citas a Canais Externos (100 pts cada):
      - "reclame aqui", "reclameaqui" â†’ +100 pts
      - "procon" â†’ +100 pts
      - "advogado", "jurÃ­dico", "processar" â†’ +100 pts cada
      - "ouvidoria" (da seguradora) â†’ +80 pts
      - "google", "avaliar", "avaliaÃ§Ã£o" â†’ +50 pts cada
   
   B. Palavras Emocionais CrÃ­ticas (30 pts cada):
      - "absurdo", "inaceitÃ¡vel", "prejuÃ­zo"
      - "indignado", "revoltado", "insatisfeito", "furioso"
   
   C. EscalaÃ§Ã£o Progressiva:
      - 2+ palavras-chave de externalizaÃ§Ã£o â†’ +100 pts bÃ´nus
      - 3+ palavras-chave â†’ +200 pts bÃ´nus
   
   D. Frases de AmeaÃ§a Direta (150 pts cada):
      - "vou publicar", "vou denunciar", "vou processar", "vou ao procon"
   
   E. PADRÃ•ES COMPORTAMENTAIS DE ESCALAÃ‡ÃƒO (150 pts mÃ¡ximo):
      
      MenÃ§Ã£o a corretor/corretora:
      - "vou falar com meu corretor", "meu corretor vai saber" â†’ +80 pts
      
      AmeaÃ§a de acionar seguradora:
      - "vou ligar na seguradora", "vou acionar o SAC" â†’ +100 pts
      - "vou falar com a [Porto/Bradesco/Azul/etc]" â†’ +100 pts
      
      MÃºltiplos canais de contato:
      - 2 canais (telefone + email) â†’ +50 pts
      - 3+ canais (telefone + email + WhatsApp) â†’ +100 pts
      
      Redes sociais:
      - "vou expor nas redes sociais" â†’ +80 pts
      - "vou postar no Facebook/Instagram/Twitter" â†’ +70 pts
      - "vou fazer um vÃ­deo" â†’ +100 pts
      
      Ultimatos:
      - "Ã© a Ãºltima vez que ligo", "Ãºltima oportunidade" â†’ +80 pts
      - "se nÃ£o resolver atÃ© [data]", "prazo de X dias" â†’ +80 pts
      - "jÃ¡ tentei X vezes" â†’ +50 pts
      
      FrustraÃ§Ã£o com processo:
      - "jÃ¡ falei com X atendentes diferentes" â†’ +70 pts
      - "cada um me dÃ¡ uma informaÃ§Ã£o diferente" â†’ +60 pts
      - "ninguÃ©m resolve nada", "nÃ£o consigo soluÃ§Ã£o" â†’ +80 pts
      - "estou hÃ¡ X dias tentando resolver" â†’ +60 pts

2. INSATISFAÃ‡ÃƒO COM RESOLUÃ‡ÃƒO ANTERIOR â€“ Peso 3 (mÃ¡ximo 300 pontos)
   - "NÃ£o resolveram", "continua o problema" â†’ +250 pts
   - "Mesma situaÃ§Ã£o de antes", "voltou a acontecer" â†’ +200 pts
   - "JÃ¡ reclamei antes" â†’ +150 pts
   - MÃºltiplas reclamaÃ§Ãµes anteriores â†’ +300 pts

3. GRAVIDADE DO CANAL ATUAL â€“ Peso 2 (mÃ¡ximo 200 pontos)
   - Ext. Ouvidoria (100 pts base): jÃ¡ crÃ­tico, risco jurÃ­dico â†’ +200 pts
   - Web - Reclame Aqui (75 pts base): risco Procon/jurÃ­dico â†’ +150 pts
   - Externo (75 pts base): risco canais formais â†’ +150 pts
   - Externo - Focais (50 pts base): risco ReclameAqui/Procon â†’ +100 pts

CÃLCULO FINAL:
1. Some todos os pontos dos fatores acima
2. Adicione o peso base do canal
3. Resultado: 0-1000 pontos (escala ampliada para melhor granularidade)
4. Classifique:
   - Baixo: 100-300 pontos
   - MÃ©dio: 301-500 pontos
   - Alto: 501-750 pontos
   - CrÃ­tico: 751-1000 pontos

FORMATO DE SAÃDA (JSON):
{{
    "risk_score": <nÃºmero de 0 a 1000>,
    "risk_level": "<Baixo/MÃ©dio/Alto/CrÃ­tico>",
    "external_indicators_score": <0-500>,
    "previous_dissatisfaction_score": <0-300>,
    "channel_gravity_score": <0-200>,
    "channel_base_score": {channel_base_score},
    "repeat_probability": "<Baixa/MÃ©dia/Alta/Muito Alta>",
    "escalation_channels": ["canal1", "canal2"],
    "previous_complaints_detected": <true/false>,
    "behavioral_patterns": ["padrÃ£o1", "padrÃ£o2"],
    "key_indicators": ["indicador1", "indicador2"],
    "urgency_level": "<Baixa/MÃ©dia/Alta/Urgente>",
    "recommendation": "<recomendaÃ§Ã£o de aÃ§Ã£o>"
}}

Retorne APENAS o JSON, sem texto adicional."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "VocÃª Ã© um analista preditivo especializado em prever escalaÃ§Ã£o de reclamaÃ§Ãµes externas usando metodologia ponderada avanÃ§ada."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1200
        )
        
        result_text = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        
        if json_match:
            result = json.loads(json_match.group())
            # Garantir que estÃ¡ na escala 100-1000
            score = result.get("risk_score", 100)
            if score < 100:
                score = 100 + score  # Ajustar para mÃ­nimo de 100
            result["risk_score"] = min(1000, score)
            return result
        else:
            return create_error_result_external(channel_base_score)
            
    except Exception as e:
        return create_error_result_external(channel_base_score, str(e))

def create_error_result(error_msg):
    """Resultado de erro para anÃ¡lise interna"""
    return {
        "risk_score": 0,
        "risk_level": "Erro",
        "frequency_score": 0,
        "delay_score": 0,
        "operational_score": 0,
        "emotional_score": 0,
        "key_factors": [error_msg],
        "detected_threats": [],
        "emotional_tone": "N/A",
        "is_technical_negative": False,
        "recommendation": "Revisar manualmente"
    }

def create_error_result_external(channel_base, error_msg="Erro na anÃ¡lise"):
    """Resultado de erro para anÃ¡lise externa"""
    return {
        "risk_score": 100 + channel_base,
        "risk_level": "Erro",
        "external_indicators_score": 0,
        "previous_dissatisfaction_score": 0,
        "channel_gravity_score": 0,
        "channel_base_score": channel_base,
        "repeat_probability": "N/A",
        "escalation_channels": [],
        "previous_complaints_detected": False,
        "behavioral_patterns": [],
        "key_indicators": [error_msg],
        "urgency_level": "N/A",
        "recommendation": "Revisar manualmente"
    }

def process_excel_file(uploaded_file, client):
    """
    Processa o arquivo Excel da planilha "Base ManifestaÃ§Ãµes"
    """
    try:
        df = pd.read_excel(uploaded_file, sheet_name='Base ManifestaÃ§Ãµes')
        
        st.info(f"ğŸ“Š Planilha 'Base ManifestaÃ§Ãµes' carregada: {len(df)} linhas, {len(df.columns)} colunas")
        
        col_names = df.columns.tolist()
        
        # Identificar colunas
        channel_col = col_names[30] if len(col_names) > 30 else None
        
        text_col = None
        for col in col_names:
            if 'HISTORICO' in str(col).upper() or 'MANIFESTACAO' in str(col).upper():
                text_col = col
                break
        
        if text_col is None:
            for col in df.columns:
                if df[col].dtype == 'object':
                    avg_length = df[col].astype(str).str.len().mean()
                    if avg_length > 100:
                        text_col = col
                        break
        
        st.write(f"**Coluna de Canal:** `{channel_col}`")
        st.write(f"**Coluna de Texto:** `{text_col}`")
        
        # Preview
        st.subheader("ğŸ“‹ Preview dos Dados")
        preview_cols = [col for col in ['NR_OCORRENCIA', channel_col, 'TIPO_MANIFESTACAO', 'SITUACAO'] if col in df.columns]
        st.dataframe(df[preview_cols].head(10) if preview_cols else df.head(10))
        
        # Processar
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        start_time = time.time()
        times_per_row = []
        
        for idx, row in df.iterrows():
            row_start = time.time()
            
            # Calcular tempo previsto
            if idx > 0:
                avg_time_per_row = sum(times_per_row) / len(times_per_row)
                remaining_rows = len(df) - (idx + 1)
                estimated_seconds = remaining_rows * avg_time_per_row
                estimated_minutes = int(estimated_seconds / 60)
                
                if estimated_minutes > 0:
                    status_text.text(f"Processando linha {idx + 1} de {len(df)}... (tempo previsto: {estimated_minutes} minutos)")
                else:
                    estimated_secs = int(estimated_seconds)
                    status_text.text(f"Processando linha {idx + 1} de {len(df)}... (tempo previsto: {estimated_secs} segundos)")
            else:
                status_text.text(f"Processando linha {idx + 1} de {len(df)}... (calculando tempo previsto...)")
            
            progress_bar.progress((idx + 1) / len(df))
            
            channel_value = row[channel_col] if channel_col else None
            text_value = row[text_col] if text_col else ""
            
            channel_type, channel_base = classify_channel_type(channel_value)
            
            nr_ocorrencia = row.get('NR_OCORRENCIA', 'N/A')
            tipo_manifestacao = row.get('TIPO_MANIFESTACAO', '')
            situacao = row.get('SITUACAO', '')
            
            full_text = f"NÃºmero: {nr_ocorrencia}\nTipo: {tipo_manifestacao}\nSituaÃ§Ã£o: {situacao}\nCanal: {channel_value}\n\nHistÃ³rico: {text_value}"
            
            if channel_type == "Interno":
                # AnÃ¡lise INTERNA: 0-100 pontos
                analysis = analyze_internal_risk(client, full_text, nr_ocorrencia)
                
                results.append({
                    "Linha": idx + 1,
                    "NR_OCORRENCIA": nr_ocorrencia,
                    "Canal Original": channel_value,
                    "Tipo": channel_type,
                    "Tipo ManifestaÃ§Ã£o": tipo_manifestacao,
                    "SituaÃ§Ã£o": situacao,
                    
                    # AnÃ¡lise Interna (0-100)
                    "Risco (0-100 ou 100-1000)": analysis.get("risk_score", 0),
                    "NÃ­vel de Risco": analysis.get("risk_level", "N/A"),
                    "Score FrequÃªncia": analysis.get("frequency_score", 0),
                    "Score Atraso": analysis.get("delay_score", 0),
                    "Score Operacional": analysis.get("operational_score", 0),
                    "Score Emocional": analysis.get("emotional_score", 0),
                    "Fatores CrÃ­ticos": ", ".join(analysis.get("key_factors", [])),
                    "AmeaÃ§as Detectadas": ", ".join(analysis.get("detected_threats", [])),
                    "Tom Emocional": analysis.get("emotional_tone", "N/A"),
                    "Negativa TÃ©cnica?": "Sim" if analysis.get("is_technical_negative", False) else "NÃ£o",
                    "RecomendaÃ§Ã£o": analysis.get("recommendation", "N/A"),
                    
                    # Campos vazios para externos
                    "PadrÃµes Comportamentais": "N/A (Interno)",
                    "Canais de EscalaÃ§Ã£o": "N/A (Interno)",
                    "ReclamaÃ§Ãµes Anteriores": "N/A (Interno)",
                    "UrgÃªncia": "N/A (Interno)"
                })
                
            else:  # Externo
                # AnÃ¡lise EXTERNA: 100-1000 pontos
                analysis = analyze_external_risk(client, full_text, nr_ocorrencia, channel_base)
                
                results.append({
                    "Linha": idx + 1,
                    "NR_OCORRENCIA": nr_ocorrencia,
                    "Canal Original": channel_value,
                    "Tipo": channel_type,
                    "Tipo ManifestaÃ§Ã£o": tipo_manifestacao,
                    "SituaÃ§Ã£o": situacao,
                    
                    # AnÃ¡lise Externa (100-1000)
                    "Risco (0-100 ou 100-1000)": analysis.get("risk_score", 100),
                    "NÃ­vel de Risco": analysis.get("risk_level", "N/A"),
                    "Score Indicadores Externos": analysis.get("external_indicators_score", 0),
                    "Score InsatisfaÃ§Ã£o Anterior": analysis.get("previous_dissatisfaction_score", 0),
                    "Score Gravidade Canal": analysis.get("channel_gravity_score", 0),
                    "Peso Base Canal": analysis.get("channel_base_score", channel_base),
                    "Probabilidade Repetir": analysis.get("repeat_probability", "N/A"),
                    "PadrÃµes Comportamentais": ", ".join(analysis.get("behavioral_patterns", [])),
                    "Canais de EscalaÃ§Ã£o": ", ".join(analysis.get("escalation_channels", [])),
                    "ReclamaÃ§Ãµes Anteriores": "Sim" if analysis.get("previous_complaints_detected", False) else "NÃ£o",
                    "Indicadores Chave": ", ".join(analysis.get("key_indicators", [])),
                    "UrgÃªncia": analysis.get("urgency_level", "N/A"),
                    "RecomendaÃ§Ã£o": analysis.get("recommendation", "N/A"),
                    
                    # Campos vazios para internos
                    "Score FrequÃªncia": "N/A (Externo)",
                    "Score Atraso": "N/A (Externo)",
                    "Score Operacional": "N/A (Externo)",
                    "Score Emocional": "N/A (Externo)",
                    "Fatores CrÃ­ticos": ", ".join(analysis.get("key_indicators", [])),
                    "AmeaÃ§as Detectadas": ", ".join(analysis.get("escalation_channels", [])),
                    "Tom Emocional": "N/A (Externo)",
                    "Negativa TÃ©cnica?": "N/A (Externo)"
                })
            
            # Registrar tempo da linha
            row_end = time.time()
            times_per_row.append(row_end - row_start)
        
        # Tempo total
        total_time = time.time() - start_time
        total_minutes = int(total_time / 60)
        total_seconds = int(total_time % 60)
        
        progress_bar.empty()
        status_text.empty()
        
        st.success(f"âœ… Processamento concluÃ­do em {total_minutes}min {total_seconds}s")
        
        return pd.DataFrame(results)
        
    except Exception as e:
        st.error(f"âŒ Erro ao processar arquivo: {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")
        return None

# Interface principal
st.title("âš ï¸ AnÃ¡lise de Risco de ExternalizaÃ§Ã£o - Base ManifestaÃ§Ãµes")
st.markdown("**Sistema com Metodologia SRO Dual AvanÃ§ada**")
st.markdown("---")

st.markdown("""
### ğŸ“Š Metodologia de AnÃ¡lise:

Esta ferramenta usa a **metodologia SRO dual avanÃ§ada** para analisar a planilha "Base ManifestaÃ§Ãµes":

#### ğŸŸ¢ **INTERNOS: 0-100 pontos** (Risco de virar externo)

**Fatores Ponderados:**
1. **FrequÃªncia de Contatos** (Peso 4) - atÃ© 40 pts
2. **Tempo de Espera/Atrasos** (Peso 3) - atÃ© 30 pts
3. **Falhas Operacionais** (Peso 2) - atÃ© 20 pts
4. **Estado Emocional** (Peso 1) - atÃ© 10 pts

**ClassificaÃ§Ã£o:**
- 0-30: ğŸŸ¢ Baixo
- 31-60: ğŸŸ¡ MÃ©dio
- 61-85: ğŸŸ  Alto
- 86-100: ğŸ”´ CrÃ­tico

#### ğŸ”´ **EXTERNOS: 100-1000 pontos** (Risco de escalaÃ§Ã£o/repetiÃ§Ã£o)

**Fatores Ponderados:**
1. **Indicadores Textuais de ExternalizaÃ§Ã£o** (Peso 5) - atÃ© 500 pts
2. **InsatisfaÃ§Ã£o com ResoluÃ§Ã£o Anterior** (Peso 3) - atÃ© 300 pts
3. **Gravidade do Canal Atual** (Peso 2) - atÃ© 200 pts

**PadrÃµes Comportamentais Detectados:**
- MenÃ§Ã£o a corretor/seguradora
- MÃºltiplos canais de contato
- AmeaÃ§as a redes sociais
- Ultimatos e prazos
- FrustraÃ§Ã£o com processo interno

**ClassificaÃ§Ã£o:**
- 100-300: ğŸŸ¢ Baixo
- 301-500: ğŸŸ¡ MÃ©dio
- 501-750: ğŸŸ  Alto
- 751-1000: ğŸ”´ CrÃ­tico

#### Pesos dos Canais Externos:
- **Ext. Ouvidoria**: 100 pontos base
- **Externo / Web - Reclame Aqui**: 75 pontos base
- **Externo - Focais**: 50 pontos base
""")

st.markdown("---")

# Upload
uploaded_file = st.file_uploader(
    "ğŸ“ FaÃ§a upload do Excel do dia (com planilha 'Base ManifestaÃ§Ãµes')",
    type=['xlsx', 'xls'],
    help="Arquivo Excel contendo a planilha 'Base ManifestaÃ§Ãµes'"
)

if uploaded_file is not None:
    st.success("âœ… Arquivo carregado!")
    
    if st.button("ğŸš€ Iniciar AnÃ¡lise Dual", type="primary"):
        with st.spinner("ğŸ” Analisando com metodologia SRO dual... Isso pode levar alguns minutos."):
            results_df = process_excel_file(uploaded_file, client)
        
        if results_df is not None:
            st.success("âœ… AnÃ¡lise concluÃ­da!")
            
            # EstatÃ­sticas
            st.subheader("ğŸ“ˆ EstatÃ­sticas Gerais")
            
            internos = results_df[results_df["Tipo"] == "Interno"]
            externos = results_df[results_df["Tipo"] == "Externo"]
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total de Casos", len(results_df))
            
            with col2:
                st.metric("Casos Internos", len(internos))
                if len(internos) > 0:
                    avg_int = internos["Risco (0-100 ou 100-1000)"].mean()
                    st.caption(f"Risco mÃ©dio: {avg_int:.1f}/100")
            
            with col3:
                st.metric("Casos Externos", len(externos))
                if len(externos) > 0:
                    avg_ext = externos["Risco (0-100 ou 100-1000)"].mean()
                    st.caption(f"Risco mÃ©dio: {avg_ext:.0f}/1000")
            
            with col4:
                criticos_int = len(internos[internos["Risco (0-100 ou 100-1000)"] >= 86])
                criticos_ext = len(externos[externos["Risco (0-100 ou 100-1000)"] >= 751])
                st.metric("Casos CrÃ­ticos", criticos_int + criticos_ext)
                st.caption(f"Int: {criticos_int} | Ext: {criticos_ext}")
            
            # DistribuiÃ§Ã£o
            st.subheader("ğŸ“Š DistribuiÃ§Ã£o por Tipo")
            col_a, col_b = st.columns(2)
            
            with col_a:
                type_dist = results_df["Tipo"].value_counts()
                st.bar_chart(type_dist)
            
            with col_b:
                st.write("**Contagem:**")
                st.dataframe(type_dist.reset_index().rename(columns={'index': 'Tipo', 'Tipo': 'Quantidade'}))
            
            # Resultados
            st.subheader("ğŸ“‹ Resultados Detalhados")
            
            def color_risk(val):
                if isinstance(val, (int, float)):
                    if val >= 751 or (val < 100 and val >= 86):  # CrÃ­tico
                        return 'background-color: #ff4444; color: white'
                    elif val >= 501 or (val < 100 and val >= 61):  # Alto
                        return 'background-color: #ff9944; color: white'
                    elif val >= 301 or (val < 100 and val >= 31):  # MÃ©dio
                        return 'background-color: #ffdd44; color: black'
                    else:  # Baixo
                        return 'background-color: #44ff44; color: black'
                return ''
            
            styled_df = results_df.style.applymap(
                color_risk,
                subset=["Risco (0-100 ou 100-1000)"]
            )
            
            st.dataframe(styled_df, use_container_width=True, height=400)
            
            # Download
            st.subheader("ğŸ’¾ Download dos Resultados")
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"analise_risco_sro_dual_{timestamp}.xlsx"
            
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                results_df.to_excel(writer, index=False, sheet_name='AnÃ¡lise de Risco SRO')
            
            st.download_button(
                label="ğŸ“¥ Baixar Resultados (Excel)",
                data=buffer.getvalue(),
                file_name=output_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # Casos prioritÃ¡rios
            st.subheader("ğŸš¨ Casos PrioritÃ¡rios")
            
            priority_int = internos[internos["Risco (0-100 ou 100-1000)"] >= 61]
            priority_ext = externos[externos["Risco (0-100 ou 100-1000)"] >= 501]
            priority_cases = pd.concat([priority_int, priority_ext]).sort_values(
                by="Risco (0-100 ou 100-1000)", ascending=False
            )
            
            if len(priority_cases) > 0:
                st.warning(f"âš ï¸ {len(priority_cases)} casos requerem atenÃ§Ã£o prioritÃ¡ria!")
                st.dataframe(
                    priority_cases[["Linha", "NR_OCORRENCIA", "Tipo", "Canal Original",
                                   "Risco (0-100 ou 100-1000)", "NÃ­vel de Risco", "RecomendaÃ§Ã£o"]],
                    use_container_width=True
                )
            else:
                st.success("âœ… Nenhum caso prioritÃ¡rio identificado!")

else:
    st.info("ğŸ‘† FaÃ§a upload de um arquivo Excel para comeÃ§ar a anÃ¡lise")

# RodapÃ©
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9em;'>
    <p><strong>AnÃ¡lise de Risco SRO Dual AvanÃ§ada</strong> | Powered by OpenAI GPT-4.1-mini</p>
    <p>ğŸ“Š Metodologia: INTERNOS (0-100) | EXTERNOS (100-1000)</p>
    <p>âš™ï¸ Configure OPENAI_API_KEY em Settings > Secrets</p>
</div>
""", unsafe_allow_html=True)
