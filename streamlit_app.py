import streamlit as st
import pandas as pd
from openai import OpenAI
import json
from datetime import datetime
import re
from io import BytesIO
import time

st.set_page_config(
    page_title="An√°lise de Risco de Externaliza√ß√£o - Base Manifesta√ß√µes",
    page_icon="‚ö†Ô∏è",
    layout="wide"
)

# Configurar OpenAI API usando secrets do Streamlit
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro ao configurar OpenAI API. Verifique se a chave est√° configurada em Settings > Secrets do Streamlit.")
    st.stop()

def classify_internal_risk(score):
    """Classifica risco interno (0-100) de forma granular"""
    if score >= 75:
        return "üî¥ RISCO ALTO DE EXTERNALIZAR"
    else:
        lower = (score // 5) * 5
        upper = lower + 5
        if upper > 74:
            upper = 74
        return f"{lower}-{upper} pts"

def classify_external_risk(score):
    """Classifica risco externo (100-1000)"""
    if score >= 851:
        return "üî¥ Vai Reclamar Novamente"
    elif score >= 701:
        return "üü† Muito Alto"
    elif score >= 501:
        return "üü° Alto"
    elif score >= 301:
        return "üü¢ M√©dio"
    else:
        return "‚ö™ Baixo"

def classify_channel_type(channel_value):
    """Classifica o canal como Interno ou Externo"""
    if pd.isna(channel_value):
        return "Interno", 0
    
    channel_str = str(channel_value).strip().lower()
    
    # Externos
    if "ouvidoria" in channel_str:
        return "Externo", 100
    elif "reclame aqui" in channel_str or "reclameaqui" in channel_str:
        return "Externo", 75
    elif "focais" in channel_str or "externo - focais" in channel_str:
        return "Externo", 50
    elif "externo" in channel_str:
        return "Externo", 75
    
    # Internos
    else:
        return "Interno", 0

def analyze_internal_risk(client, text, nr_ocorrencia="N/A"):
    """EIXO 1: An√°lise de risco de reclama√ß√µes INTERNAS virarem EXTERNAS (0-100 pontos)"""
    
    prompt = f"""Voc√™ √© um analista preditivo especializado em prever o risco de reclama√ß√µes internas se tornarem externas.

CONTEXTO:
Esta √© uma reclama√ß√£o INTERNA (NR_OCORRENCIA: {nr_ocorrencia})

TEXTO DA RECLAMA√á√ÉO:
{text}

TAREFA:
Analise o texto e calcule o risco (0-100 pontos) de esta reclama√ß√£o INTERNA se tornar EXTERNA (ReclameAqui, Procon, Ouvidoria).

METODOLOGIA DE AN√ÅLISE (EIXO 1):

Fatores Preditivos e Pesos:

1. FREQU√äNCIA DE CONTATOS ‚Äì Peso 4 (m√°ximo 40 pontos)
   - 1 contato: 0 pts
   - 2 contatos: 5 pts
   - 3+ contatos: 10 pts

2. TEMPO DE ESPERA / ATRASOS ‚Äì Peso 3 (m√°ximo 30 pontos)
   - Men√ß√£o a atrasos: +10 pts
   - Men√ß√£o a "dias", "semanas" de espera: +10 pts
   - Men√ß√£o a prazos n√£o cumpridos: +10 pts

3. FALHAS OPERACIONAIS ‚Äì Peso 2 (m√°ximo 20 pontos)
   - Ind√≠cios t√©cnicos graves: 10 pts cada
   - Falhas de processo: 5 pts cada

4. ESTADO EMOCIONAL ‚Äì Peso 1 (m√°ximo 10 pontos)
   - Termos negativos moderados: 1 pt cada
   - Termos de risco jur√≠dico: 3 pts cada
   - Termos positivos: -1 pt cada

REGRA ESPECIAL: Negativas t√©cnicas sem insatisfa√ß√£o = m√°ximo 30 pontos

FORMATO DE SA√çDA (JSON):
{{
    "risk_score": <n√∫mero de 0 a 100>,
    "frequency_score": <0-40>,
    "delay_score": <0-30>,
    "operational_score": <0-20>,
    "emotional_score": <0-10>,
    "key_factors": ["fator1", "fator2"],
    "detected_threats": ["amea√ßa1", "amea√ßa2"],
    "emotional_tone": "<descri√ß√£o>",
    "is_technical_negative": <true/false>,
    "recommendation": "<recomenda√ß√£o>"
}}

Retorne APENAS o JSON."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista preditivo especializado."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=800
        )
        
        result_text = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        
        if json_match:
            return json.loads(json_match.group())
        else:
            return create_error_result("Erro ao processar resposta")
            
    except Exception as e:
        return create_error_result(str(e))

def analyze_external_risk(client, text, nr_ocorrencia="N/A", channel_base_score=50):
    """EIXO 2: An√°lise de risco de reclama√ß√µes EXTERNAS serem ESCALADAS/REPETIDAS (100-1000 pontos)"""
    
    prompt = f"""Voc√™ √© um analista preditivo especializado em prever escala√ß√£o de reclama√ß√µes externas.

CONTEXTO:
Esta √© uma reclama√ß√£o EXTERNA (NR_OCORRENCIA: {nr_ocorrencia})
Peso base do canal: {channel_base_score} pontos

TEXTO DA RECLAMA√á√ÉO:
{text}

TAREFA:
Analise o texto e calcule o risco (100-1000 pontos) de o cliente ESCALAR ou RECLAMAR NOVAMENTE.

METODOLOGIA DE AN√ÅLISE (EIXO 2):

1. INDICADORES TEXTUAIS ‚Äì Peso 5 (m√°ximo 500 pontos)
   - Men√ß√µes a canais externos: 100 pts cada
   - Palavras emocionais cr√≠ticas: 30 pts cada
   - Amea√ßas diretas: 150 pts cada
   - Padr√µes comportamentais: at√© 150 pts

2. INSATISFA√á√ÉO ANTERIOR ‚Äì Peso 3 (m√°ximo 300 pontos)
   - "N√£o resolveram": +250 pts
   - "Voltou a acontecer": +200 pts
   - "J√° reclamei antes": +150 pts

3. GRAVIDADE DO CANAL ‚Äì Peso 2 (m√°ximo 200 pontos)
   - Baseado no peso base do canal

FORMATO DE SA√çDA (JSON):
{{
    "risk_score": <n√∫mero de 100 a 1000>,
    "external_indicators_score": <0-500>,
    "previous_dissatisfaction_score": <0-300>,
    "channel_gravity_score": <0-200>,
    "channel_base_score": {channel_base_score},
    "repeat_probability": "<Baixa/M√©dia/Alta/Muito Alta/Certeza>",
    "escalation_channels": ["canal1", "canal2"],
    "previous_complaints_detected": <true/false>,
    "behavioral_patterns": ["padr√£o1", "padr√£o2"],
    "key_indicators": ["indicador1", "indicador2"],
    "urgency_level": "<Baixa/M√©dia/Alta/Urgente>",
    "recommendation": "<recomenda√ß√£o>"
}}

Retorne APENAS o JSON."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista preditivo especializado."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1000
        )
        
        result_text = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        
        if json_match:
            result = json.loads(json_match.group())
            score = result.get("risk_score", 100)
            if score < 100:
                score = 100 + score
            result["risk_score"] = min(1000, score)
            return result
        else:
            return create_error_result_external(channel_base_score)
            
    except Exception as e:
        return create_error_result_external(channel_base_score, str(e))

def create_error_result(error_msg):
    """Resultado de erro para an√°lise interna"""
    return {
        "risk_score": 0,
        "frequency_score": 0,
        "delay_score": 0,
        "operational_score": 0,
        "emotional_score": 0,
        "key_factors": [error_msg],
        "detected_threats": [],
        "emotional_tone": "N/A",
        "is_technical_negative": False,
        "recommendation": "Revisar manualmente"
    }

def create_error_result_external(channel_base, error_msg="Erro na an√°lise"):
    """Resultado de erro para an√°lise externa"""
    return {
        "risk_score": 100 + channel_base,
        "external_indicators_score": 0,
        "previous_dissatisfaction_score": 0,
        "channel_gravity_score": 0,
        "channel_base_score": channel_base,
        "repeat_probability": "N/A",
        "escalation_channels": [],
        "previous_complaints_detected": False,
        "behavioral_patterns": [],
        "key_indicators": [error_msg],
        "urgency_level": "N/A",
        "recommendation": "Revisar manualmente"
    }

def process_internals_only(uploaded_file, client):
    """Processa APENAS reclama√ß√µes INTERNAS"""
    try:
        df = pd.read_excel(uploaded_file, sheet_name='Base Manifesta√ß√µes')
        
        col_names = df.columns.tolist()
        channel_col = col_names[30] if len(col_names) > 30 else None
        
        text_col = None
        for col in col_names:
            if 'HISTORICO' in str(col).upper() or 'MANIFESTACAO' in str(col).upper():
                text_col = col
                break
        
        if text_col is None:
            for col in df.columns:
                if df[col].dtype == 'object':
                    avg_length = df[col].astype(str).str.len().mean()
                    if avg_length > 100:
                        text_col = col
                        break
        
        # Filtrar apenas INTERNOS
        df_filtered = df.copy()
        df_filtered['_channel_type'] = df_filtered[channel_col].apply(lambda x: classify_channel_type(x)[0])
        df_internos = df_filtered[df_filtered['_channel_type'] == 'Interno'].copy()
        
        st.info(f"üìä Total de linhas: {len(df)} | **Internos: {len(df_internos)}** | Externos: {len(df) - len(df_internos)}")
        
        if len(df_internos) == 0:
            st.warning("‚ö†Ô∏è Nenhuma reclama√ß√£o interna encontrada!")
            return None
        
        # Processar
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        start_time = time.time()
        times_per_row = []
        
        for idx, (orig_idx, row) in enumerate(df_internos.iterrows()):
            try:
                row_start = time.time()
                
                # Calcular tempo previsto
                if idx > 0:
                    avg_time_per_row = sum(times_per_row) / len(times_per_row)
                    remaining_rows = len(df_internos) - (idx + 1)
                    estimated_seconds = remaining_rows * avg_time_per_row
                    estimated_minutes = int(estimated_seconds / 60)
                    
                    if estimated_minutes > 0:
                        status_text.text(f"Processando INTERNO {idx + 1} de {len(df_internos)}... (tempo previsto: {estimated_minutes} minutos)")
                    else:
                        estimated_secs = int(estimated_seconds)
                        status_text.text(f"Processando INTERNO {idx + 1} de {len(df_internos)}... (tempo previsto: {estimated_secs} segundos)")
                else:
                    status_text.text(f"Processando INTERNO {idx + 1} de {len(df_internos)}... (calculando tempo previsto...)")
                
                progress_bar.progress((idx + 1) / len(df_internos))
                
                channel_value = row[channel_col] if channel_col else None
                text_value = row[text_col] if text_col else ""
                
                nr_ocorrencia = row.get('NR_OCORRENCIA', 'N/A')
                tipo_manifestacao = row.get('TIPO_MANIFESTACAO', '')
                situacao = row.get('SITUACAO', '')
                
                full_text = f"N√∫mero: {nr_ocorrencia}\nTipo: {tipo_manifestacao}\nSitua√ß√£o: {situacao}\nCanal: {channel_value}\n\nHist√≥rico: {text_value}"
                
                # An√°lise INTERNA
                analysis = analyze_internal_risk(client, full_text, nr_ocorrencia)
                score = analysis.get("risk_score", 0)
                classification = classify_internal_risk(score)
                
                results.append({
                    "Linha Original": orig_idx + 1,
                    "NR_OCORRENCIA": nr_ocorrencia,
                    "Canal": channel_value,
                    "Tipo Manifesta√ß√£o": tipo_manifestacao,
                    "Situa√ß√£o": situacao,
                    "Pontua√ß√£o": score,
                    "Classifica√ß√£o": classification,
                    "Score Frequ√™ncia": analysis.get("frequency_score", 0),
                    "Score Atraso": analysis.get("delay_score", 0),
                    "Score Operacional": analysis.get("operational_score", 0),
                    "Score Emocional": analysis.get("emotional_score", 0),
                    "Fatores Cr√≠ticos": ", ".join(analysis.get("key_factors", [])),
                    "Amea√ßas Detectadas": ", ".join(analysis.get("detected_threats", [])),
                    "Tom Emocional": analysis.get("emotional_tone", "N/A"),
                    "Negativa T√©cnica?": "Sim" if analysis.get("is_technical_negative", False) else "N√£o",
                    "Recomenda√ß√£o": analysis.get("recommendation", "N/A")
                })
                
                row_end = time.time()
                times_per_row.append(row_end - row_start)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro na linha {orig_idx + 1}: {str(e)}")
                continue
        
        total_time = time.time() - start_time
        total_minutes = int(total_time / 60)
        total_seconds = int(total_time % 60)
        
        progress_bar.empty()
        status_text.empty()
        
        st.success(f"‚úÖ An√°lise de INTERNOS conclu√≠da em {total_minutes}min {total_seconds}s")
        
        return pd.DataFrame(results)
        
    except Exception as e:
        st.error(f"‚ùå Erro: {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")
        return None

def process_externals_only(uploaded_file, client):
    """Processa APENAS reclama√ß√µes EXTERNAS"""
    try:
        df = pd.read_excel(uploaded_file, sheet_name='Base Manifesta√ß√µes')
        
        col_names = df.columns.tolist()
        channel_col = col_names[30] if len(col_names) > 30 else None
        
        text_col = None
        for col in col_names:
            if 'HISTORICO' in str(col).upper() or 'MANIFESTACAO' in str(col).upper():
                text_col = col
                break
        
        if text_col is None:
            for col in df.columns:
                if df[col].dtype == 'object':
                    avg_length = df[col].astype(str).str.len().mean()
                    if avg_length > 100:
                        text_col = col
                        break
        
        # Filtrar apenas EXTERNOS
        df_filtered = df.copy()
        df_filtered['_channel_info'] = df_filtered[channel_col].apply(classify_channel_type)
        df_filtered['_channel_type'] = df_filtered['_channel_info'].apply(lambda x: x[0])
        df_filtered['_channel_base'] = df_filtered['_channel_info'].apply(lambda x: x[1])
        df_externos = df_filtered[df_filtered['_channel_type'] == 'Externo'].copy()
        
        st.info(f"üìä Total de linhas: {len(df)} | Internos: {len(df) - len(df_externos)} | **Externos: {len(df_externos)}**")
        
        if len(df_externos) == 0:
            st.warning("‚ö†Ô∏è Nenhuma reclama√ß√£o externa encontrada!")
            return None
        
        # Processar
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        start_time = time.time()
        times_per_row = []
        
        for idx, (orig_idx, row) in enumerate(df_externos.iterrows()):
            try:
                row_start = time.time()
                
                # Calcular tempo previsto
                if idx > 0:
                    avg_time_per_row = sum(times_per_row) / len(times_per_row)
                    remaining_rows = len(df_externos) - (idx + 1)
                    estimated_seconds = remaining_rows * avg_time_per_row
                    estimated_minutes = int(estimated_seconds / 60)
                    
                    if estimated_minutes > 0:
                        status_text.text(f"Processando EXTERNO {idx + 1} de {len(df_externos)}... (tempo previsto: {estimated_minutes} minutos)")
                    else:
                        estimated_secs = int(estimated_seconds)
                        status_text.text(f"Processando EXTERNO {idx + 1} de {len(df_externos)}... (tempo previsto: {estimated_secs} segundos)")
                else:
                    status_text.text(f"Processando EXTERNO {idx + 1} de {len(df_externos)}... (calculando tempo previsto...)")
                
                progress_bar.progress((idx + 1) / len(df_externos))
                
                channel_value = row[channel_col] if channel_col else None
                text_value = row[text_col] if text_col else ""
                channel_base = row['_channel_base']
                
                nr_ocorrencia = row.get('NR_OCORRENCIA', 'N/A')
                tipo_manifestacao = row.get('TIPO_MANIFESTACAO', '')
                situacao = row.get('SITUACAO', '')
                
                full_text = f"N√∫mero: {nr_ocorrencia}\nTipo: {tipo_manifestacao}\nSitua√ß√£o: {situacao}\nCanal: {channel_value}\n\nHist√≥rico: {text_value}"
                
                # An√°lise EXTERNA
                analysis = analyze_external_risk(client, full_text, nr_ocorrencia, channel_base)
                score = analysis.get("risk_score", 100)
                classification = classify_external_risk(score)
                
                results.append({
                    "Linha Original": orig_idx + 1,
                    "NR_OCORRENCIA": nr_ocorrencia,
                    "Canal": channel_value,
                    "Tipo Manifesta√ß√£o": tipo_manifestacao,
                    "Situa√ß√£o": situacao,
                    "Pontua√ß√£o": score,
                    "Classifica√ß√£o": classification,
                    "Score Indicadores Externos": analysis.get("external_indicators_score", 0),
                    "Score Insatisfa√ß√£o Anterior": analysis.get("previous_dissatisfaction_score", 0),
                    "Score Gravidade Canal": analysis.get("channel_gravity_score", 0),
                    "Peso Base Canal": analysis.get("channel_base_score", channel_base),
                    "Probabilidade Repetir": analysis.get("repeat_probability", "N/A"),
                    "Padr√µes Comportamentais": ", ".join(analysis.get("behavioral_patterns", [])),
                    "Canais de Escala√ß√£o": ", ".join(analysis.get("escalation_channels", [])),
                    "Reclama√ß√µes Anteriores": "Sim" if analysis.get("previous_complaints_detected", False) else "N√£o",
                    "Indicadores Chave": ", ".join(analysis.get("key_indicators", [])),
                    "Urg√™ncia": analysis.get("urgency_level", "N/A"),
                    "Recomenda√ß√£o": analysis.get("recommendation", "N/A")
                })
                
                row_end = time.time()
                times_per_row.append(row_end - row_start)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro na linha {orig_idx + 1}: {str(e)}")
                continue
        
        total_time = time.time() - start_time
        total_minutes = int(total_time / 60)
        total_seconds = int(total_time % 60)
        
        progress_bar.empty()
        status_text.empty()
        
        st.success(f"‚úÖ An√°lise de EXTERNOS conclu√≠da em {total_minutes}min {total_seconds}s")
        
        return pd.DataFrame(results)
        
    except Exception as e:
        st.error(f"‚ùå Erro: {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")
        return None

# Interface principal
st.title("‚ö†Ô∏è An√°lise de Risco de Externaliza√ß√£o - Base Manifesta√ß√µes")
st.markdown("**Sistema com Metodologia SRO Dual Avan√ßada - An√°lises Separadas**")
st.markdown("---")

st.markdown("""
### üìä Metodologia de An√°lise:

#### üü¢ **INTERNOS: 0-100 pontos** (Risco de virar externo)
- **0-74 pontos**: Classifica√ß√£o granular (0-5, 5-10... 70-74)
- **75-100 pontos**: üî¥ **RISCO ALTO DE EXTERNALIZAR**

#### üî¥ **EXTERNOS: 100-1000 pontos** (Risco de escala√ß√£o/repeti√ß√£o)
- **100-300**: ‚ö™ Baixo
- **301-500**: üü¢ M√©dio
- **501-700**: üü° Alto
- **701-850**: üü† Muito Alto
- **851-1000**: üî¥ **Vai Reclamar Novamente**

### üí° **Estrat√©gia de Processamento:**
Para evitar timeout, as an√°lises foram separadas em dois bot√µes:
1. **Analisar INTERNOS** ‚Üí Gera Excel com internos
2. **Analisar EXTERNOS** ‚Üí Gera Excel com externos

Voc√™ pode processar um de cada vez e depois juntar os resultados!
""")

st.markdown("---")

# Upload
uploaded_file = st.file_uploader(
    "üìÅ Fa√ßa upload do Excel do dia (com planilha 'Base Manifesta√ß√µes')",
    type=['xlsx', 'xls'],
    help="Arquivo Excel contendo a planilha 'Base Manifesta√ß√µes'"
)

if uploaded_file is not None:
    st.success("‚úÖ Arquivo carregado!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üü¢ Analisar INTERNOS (0-100)", type="primary", use_container_width=True):
            with st.spinner("üîç Analisando reclama√ß√µes INTERNAS..."):
                results_df = process_internals_only(uploaded_file, client)
            
            if results_df is not None:
                st.success("‚úÖ An√°lise de INTERNOS conclu√≠da!")
                
                # Estat√≠sticas
                st.subheader("üìà Estat√≠sticas - INTERNOS")
                
                col_a, col_b, col_c = st.columns(3)
                
                with col_a:
                    st.metric("Total Internos", len(results_df))
                
                with col_b:
                    avg_score = results_df["Pontua√ß√£o"].mean()
                    st.metric("Pontua√ß√£o M√©dia", f"{avg_score:.1f}/100")
                
                with col_c:
                    criticos = len(results_df[results_df["Pontua√ß√£o"] >= 75])
                    st.metric("Casos Cr√≠ticos (‚â•75)", criticos)
                
                # Resultados
                st.subheader("üìã Resultados - INTERNOS")
                st.dataframe(results_df, use_container_width=True, height=400)
                
                # Download
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"analise_internos_{timestamp}.xlsx"
                
                buffer = BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    results_df.to_excel(writer, index=False, sheet_name='Internos')
                
                st.download_button(
                    label="üì• Baixar Resultados INTERNOS (Excel)",
                    data=buffer.getvalue(),
                    file_name=output_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
    
    with col2:
        if st.button("üî¥ Analisar EXTERNOS (100-1000)", type="secondary", use_container_width=True):
            with st.spinner("üîç Analisando reclama√ß√µes EXTERNAS..."):
                results_df = process_externals_only(uploaded_file, client)
            
            if results_df is not None:
                st.success("‚úÖ An√°lise de EXTERNOS conclu√≠da!")
                
                # Estat√≠sticas
                st.subheader("üìà Estat√≠sticas - EXTERNOS")
                
                col_a, col_b, col_c = st.columns(3)
                
                with col_a:
                    st.metric("Total Externos", len(results_df))
                
                with col_b:
                    avg_score = results_df["Pontua√ß√£o"].mean()
                    st.metric("Pontua√ß√£o M√©dia", f"{avg_score:.0f}/1000")
                
                with col_c:
                    criticos = len(results_df[results_df["Pontua√ß√£o"] >= 851])
                    st.metric("Vai Reclamar (‚â•851)", criticos)
                
                # Resultados
                st.subheader("üìã Resultados - EXTERNOS")
                st.dataframe(results_df, use_container_width=True, height=400)
                
                # Download
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"analise_externos_{timestamp}.xlsx"
                
                buffer = BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    results_df.to_excel(writer, index=False, sheet_name='Externos')
                
                st.download_button(
                    label="üì• Baixar Resultados EXTERNOS (Excel)",
                    data=buffer.getvalue(),
                    file_name=output_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

else:
    st.info("üëÜ Fa√ßa upload de um arquivo Excel para come√ßar a an√°lise")

# Rodap√©
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9em;'>
    <p><strong>An√°lise de Risco SRO Dual Avan√ßada</strong> | Powered by OpenAI GPT-4.1-mini</p>
    <p>üìä Metodologia: INTERNOS (0-100 granular) | EXTERNOS (100-1000 com 5 n√≠veis)</p>
    <p>‚öôÔ∏è Configure OPENAI_API_KEY em Settings > Secrets</p>
    <p>üí° An√°lises separadas para evitar timeout do Streamlit Cloud</p>
</div>
""", unsafe_allow_html=True)
