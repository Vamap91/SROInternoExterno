import streamlit as st
import pandas as pd
import openai
from openai import OpenAI
import json
from datetime import datetime
import re

st.set_page_config(
    page_title="An√°lise de Risco de Externaliza√ß√£o",
    page_icon="‚ö†Ô∏è",
    layout="wide"
)

# Configurar OpenAI API usando secrets do Streamlit
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro ao configurar OpenAI API. Verifique se a chave est√° configurada em Settings > Secrets do Streamlit.")
    st.stop()

def classify_channel_risk(channel_value):
    """
    Classifica o peso de risco baseado no canal (coluna CANAL_DE_ENTRADA_MANIFESTACAO)
    
    Pesos conforme solicitado:
    - Ext. Ouvidoria: 100 pontos (mais cr√≠tico)
    - Externo / Web - Reclame Aqui: 75 pontos
    - Externo - Focais: 50 pontos
    - Interno: 0 pontos (para an√°lise de externaliza√ß√£o)
    """
    if pd.isna(channel_value):
        return 0, "N√£o classificado"
    
    channel_str = str(channel_value).strip().lower()
    
    # Ext. Ouvidoria - 100 pontos (mais cr√≠tico)
    if "ouvidoria" in channel_str:
        return 100, "Ext. Ouvidoria"
    
    # Web - Reclame Aqui / Externo (sem focais) - 75 pontos
    elif "reclame aqui" in channel_str or "reclameaqui" in channel_str:
        return 75, "Web - Reclame Aqui"
    elif "externo" in channel_str and "focais" not in channel_str:
        return 75, "Externo"
    
    # Externo - Focais - 50 pontos
    elif "focais" in channel_str or "ext. focais" in channel_str or "externo - focais" in channel_str:
        return 50, "Externo - Focais"
    
    # Interno - 0 pontos
    elif "interno" in channel_str or "interna" in channel_str:
        return 0, "Interno"
    
    else:
        return 0, "N√£o classificado"

def analyze_internal_to_external_risk(client, text_content, channel_type):
    """
    An√°lise 1: Risco de reclama√ß√µes INTERNAS virarem EXTERNAS (0-100)
    """
    
    prompt = f"""Voc√™ √© um analista de risco especializado em prever a probabilidade de reclama√ß√µes internas se tornarem externas.

CONTEXTO:
Esta √© uma reclama√ß√£o atualmente classificada como: {channel_type}

TEXTO DA RECLAMA√á√ÉO:
{text_content}

TAREFA:
Analise o texto e calcule o risco (0-100) de esta reclama√ß√£o se tornar externa (ReclameAqui, Procon, Ouvidoria).

FATORES A CONSIDERAR (pontua√ß√£o 0-100):

1. INDICADORES DE EXTERNALIZA√á√ÉO (peso alto):
   - Men√ß√µes a "ReclameAqui", "Procon", "advogado", "processar": +20 pts cada
   - Men√ß√µes a "ouvidoria", "√≥rg√£o de defesa": +15 pts cada
   - Amea√ßas diretas ("vou publicar", "vou denunciar"): +25 pts cada
   - Men√ß√£o a corretor/corretora: +10 pts
   - M√∫ltiplos canais de contato: +10 pts

2. ESTADO EMOCIONAL (peso m√©dio):
   - Palavras cr√≠ticas ("absurdo", "inaceit√°vel", "revoltado", "indignado"): +5 pts cada
   - Frustra√ß√£o com processo ("ningu√©m resolve", "j√° tentei X vezes"): +10 pts
   - Ultimatos ("√∫ltima vez", "prazo de X dias"): +15 pts

3. GRAVIDADE DO PROBLEMA (peso m√©dio):
   - Problemas t√©cnicos graves (defeito, dano, preju√≠zo, mal feito, torto, amassado): +10 pts
   - M√∫ltiplas tentativas sem resolu√ß√£o: +15 pts
   - Tempo de espera excessivo (muitos dias): +10 pts
   - Falta de cuidado/qualidade: +10 pts

4. ATENUANTES (reduzem risco):
   - Negativa t√©cnica sem insatisfa√ß√£o expl√≠cita: -20 pts
   - Procedimentos administrativos padr√£o: -10 pts
   - Palavras positivas ou neutras: -5 pts cada

FORMATO DE SA√çDA (JSON):
{{
    "risk_score": <n√∫mero de 0 a 100>,
    "risk_level": "<Baixo/M√©dio/Alto/Cr√≠tico>",
    "key_factors": ["fator1", "fator2", "fator3"],
    "detected_threats": ["amea√ßa1", "amea√ßa2"],
    "emotional_tone": "<descri√ß√£o breve do tom emocional>",
    "recommendation": "<recomenda√ß√£o de a√ß√£o>"
}}

CLASSIFICA√á√ÉO:
- Baixo: 0-30
- M√©dio: 31-60
- Alto: 61-85
- Cr√≠tico: 86-100

Retorne APENAS o JSON, sem texto adicional."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista de risco especializado em prever externaliza√ß√µes de reclama√ß√µes."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=800
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Extrair JSON da resposta
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            return result
        else:
            return {
                "risk_score": 0,
                "risk_level": "Erro",
                "key_factors": ["Erro ao processar resposta"],
                "detected_threats": [],
                "emotional_tone": "N/A",
                "recommendation": "Revisar manualmente"
            }
    except Exception as e:
        st.error(f"Erro na an√°lise: {str(e)}")
        return {
            "risk_score": 0,
            "risk_level": "Erro",
            "key_factors": [str(e)],
            "detected_threats": [],
            "emotional_tone": "N/A",
            "recommendation": "Erro na an√°lise"
        }

def analyze_external_repeat_risk(client, text_content, channel_type, channel_risk_score):
    """
    An√°lise 2: Risco de reclama√ß√µes EXTERNAS serem REPETIDAS/ESCALADAS (0-100)
    """
    
    prompt = f"""Voc√™ √© um analista de risco especializado em prever reincid√™ncia e escala√ß√£o de reclama√ß√µes externas.

CONTEXTO:
Esta √© uma reclama√ß√£o EXTERNA classificada como: {channel_type}
Peso base do canal: {channel_risk_score} pontos

TEXTO DA RECLAMA√á√ÉO:
{text_content}

TAREFA:
Analise o texto e calcule o risco (0-100) de o cliente RECLAMAR NOVAMENTE ou ESCALAR para outros canais.

FATORES A CONSIDERAR:

1. INSATISFA√á√ÉO COM RESOLU√á√ÉO ANTERIOR (peso cr√≠tico):
   - "N√£o resolveram", "continua o problema": +25 pts
   - "Mesma situa√ß√£o de antes", "voltou a acontecer": +20 pts
   - "J√° reclamei antes": +15 pts
   - Men√ß√£o a m√∫ltiplas reclama√ß√µes anteriores: +30 pts

2. ESCALA√á√ÉO PROGRESSIVA (peso alto):
   - Men√ß√£o a canais adicionais ("agora vou ao Procon", "vou processar"): +25 pts cada
   - Amea√ßas jur√≠dicas ap√≥s reclama√ß√£o externa: +35 pts
   - Men√ß√£o a advogado ap√≥s ReclameAqui: +40 pts
   - "√öltima tentativa antes de processar": +45 pts

3. GRAVIDADE DO CANAL ATUAL (peso base):
   - Ext. Ouvidoria (100 pts): j√° √© cr√≠tico, risco de a√ß√£o jur√≠dica
   - Web - Reclame Aqui (75 pts): risco de Procon/jur√≠dico
   - Externo (75 pts): risco de canais formais
   - Externo - Focais (50 pts): risco de ReclameAqui/Procon

4. ESTADO EMOCIONAL ATUAL (peso m√©dio):
   - Frustra√ß√£o extrema ("cansado", "desistindo"): +20 pts
   - Raiva/indigna√ß√£o crescente: +15 pts
   - Men√ß√£o a preju√≠zo financeiro/tempo: +10 pts

5. PADR√ÉO DE COMPORTAMENTO (peso m√©dio):
   - Cliente persistente (m√∫ltiplos contatos): +15 pts
   - Cliente documenta tudo: +10 pts
   - Cliente menciona prazos legais: +20 pts

FORMATO DE SA√çDA (JSON):
{{
    "risk_score": <n√∫mero de 0 a 100>,
    "risk_level": "<Baixo/M√©dio/Alto/Cr√≠tico>",
    "repeat_probability": "<Baixa/M√©dia/Alta/Muito Alta>",
    "escalation_channels": ["canal1", "canal2"],
    "previous_complaints_detected": <true/false>,
    "key_indicators": ["indicador1", "indicador2"],
    "urgency_level": "<Baixa/M√©dia/Alta/Urgente>",
    "recommendation": "<recomenda√ß√£o de a√ß√£o>"
}}

CLASSIFICA√á√ÉO:
- Baixo: 0-30 (improv√°vel repetir)
- M√©dio: 31-60 (pode reclamar novamente)
- Alto: 61-85 (prov√°vel escala√ß√£o)
- Cr√≠tico: 86-100 (escala√ß√£o iminente)

Retorne APENAS o JSON, sem texto adicional."""

    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista de risco especializado em prever reincid√™ncia de reclama√ß√µes."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=800
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Extrair JSON da resposta
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            # Ajustar score baseado no peso do canal
            base_score = result.get("risk_score", 0)
            adjusted_score = min(100, int(base_score * 0.6 + channel_risk_score * 0.4))
            result["risk_score"] = adjusted_score
            result["channel_base_score"] = channel_risk_score
            return result
        else:
            return {
                "risk_score": channel_risk_score,
                "risk_level": "Erro",
                "repeat_probability": "N/A",
                "escalation_channels": [],
                "previous_complaints_detected": False,
                "key_indicators": ["Erro ao processar resposta"],
                "urgency_level": "N/A",
                "recommendation": "Revisar manualmente",
                "channel_base_score": channel_risk_score
            }
    except Exception as e:
        st.error(f"Erro na an√°lise: {str(e)}")
        return {
            "risk_score": channel_risk_score,
            "risk_level": "Erro",
            "repeat_probability": "N/A",
            "escalation_channels": [],
            "previous_complaints_detected": False,
            "key_indicators": [str(e)],
            "urgency_level": "N/A",
            "recommendation": "Erro na an√°lise",
            "channel_base_score": channel_risk_score
        }

def process_excel_file(uploaded_file, client):
    """
    Processa o arquivo Excel da planilha "Base Manifesta√ß√µes" e analisa cada linha
    """
    try:
        # Ler planilha "Base Manifesta√ß√µes"
        df = pd.read_excel(uploaded_file, sheet_name='Base Manifesta√ß√µes')
        
        st.info(f"üìä Planilha 'Base Manifesta√ß√µes' carregada: {len(df)} linhas, {len(df.columns)} colunas")
        
        # Identificar colunas importantes
        col_names = df.columns.tolist()
        
        # Coluna de canal (√≠ndice 30 = CANAL_DE_ENTRADA_MANIFESTACAO)
        channel_col = col_names[30] if len(col_names) > 30 else None
        
        # Coluna de hist√≥rico/texto (geralmente cont√©m "HISTORICO" ou similar)
        text_col = None
        for col in col_names:
            if 'HISTORICO' in str(col).upper() or 'MANIFESTACAO' in str(col).upper() or 'DESCRICAO' in str(col).upper():
                text_col = col
                break
        
        # Se n√£o encontrou, buscar coluna com textos longos
        if text_col is None:
            for col in df.columns:
                if df[col].dtype == 'object':
                    avg_length = df[col].astype(str).str.len().mean()
                    if avg_length > 100:  # Coluna com textos longos
                        text_col = col
                        break
        
        st.write(f"**Coluna de Canal:** `{channel_col}`")
        st.write(f"**Coluna de Texto:** `{text_col}`")
        
        # Mostrar preview
        st.subheader("üìã Preview dos Dados")
        preview_cols = [col for col in ['NR_OCORRENCIA', channel_col, 'TIPO_MANIFESTACAO', 'SITUACAO', text_col] if col in df.columns]
        st.dataframe(df[preview_cols].head(10) if preview_cols else df.head(10))
        
        # Processar cada linha
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for idx, row in df.iterrows():
            status_text.text(f"Processando linha {idx + 1} de {len(df)}...")
            progress_bar.progress((idx + 1) / len(df))
            
            # Obter canal e texto
            channel_value = row[channel_col] if channel_col else None
            text_value = row[text_col] if text_col else ""
            
            # Classificar risco do canal
            channel_risk, channel_type = classify_channel_risk(channel_value)
            
            # Concatenar informa√ß√µes relevantes para an√°lise
            nr_ocorrencia = row.get('NR_OCORRENCIA', 'N/A')
            tipo_manifestacao = row.get('TIPO_MANIFESTACAO', '')
            situacao = row.get('SITUACAO', '')
            
            full_text = f"N√∫mero da Ocorr√™ncia: {nr_ocorrencia}\n"
            full_text += f"Tipo: {tipo_manifestacao}\n"
            full_text += f"Situa√ß√£o: {situacao}\n"
            full_text += f"Canal: {channel_value}\n\n"
            full_text += f"Hist√≥rico: {text_value}"
            
            if not full_text or len(full_text.strip()) < 20:
                full_text = "Sem informa√ß√µes textuais dispon√≠veis"
            
            # An√°lise 1: Risco de interna virar externa
            analysis1 = analyze_internal_to_external_risk(client, full_text, channel_type)
            
            # An√°lise 2: Risco de externa repetir (s√≥ para externas)
            if channel_risk > 0:  # √â externa
                analysis2 = analyze_external_repeat_risk(client, full_text, channel_type, channel_risk)
            else:  # √â interna
                analysis2 = {
                    "risk_score": 0,
                    "risk_level": "N/A (Interna)",
                    "repeat_probability": "N/A",
                    "escalation_channels": [],
                    "previous_complaints_detected": False,
                    "key_indicators": ["Reclama√ß√£o interna"],
                    "urgency_level": "N/A",
                    "recommendation": "Monitorar para evitar externaliza√ß√£o",
                    "channel_base_score": 0
                }
            
            results.append({
                "Linha": idx + 1,
                "NR_OCORRENCIA": nr_ocorrencia,
                "Canal Original": channel_value,
                "Canal Classificado": channel_type,
                "Peso do Canal": channel_risk,
                "Tipo Manifesta√ß√£o": tipo_manifestacao,
                "Situa√ß√£o": situacao,
                
                # An√°lise 1: Interno ‚Üí Externo
                "Risco Interno‚ÜíExterno (0-100)": analysis1.get("risk_score", 0),
                "N√≠vel Risco Int‚ÜíExt": analysis1.get("risk_level", "N/A"),
                "Fatores Cr√≠ticos Int‚ÜíExt": ", ".join(analysis1.get("key_factors", [])),
                "Amea√ßas Detectadas": ", ".join(analysis1.get("detected_threats", [])),
                "Tom Emocional": analysis1.get("emotional_tone", "N/A"),
                
                # An√°lise 2: Externo ‚Üí Repeti√ß√£o
                "Risco Repeti√ß√£o Externa (0-100)": analysis2.get("risk_score", 0),
                "N√≠vel Risco Repeti√ß√£o": analysis2.get("risk_level", "N/A"),
                "Probabilidade Repetir": analysis2.get("repeat_probability", "N/A"),
                "Canais de Escala√ß√£o": ", ".join(analysis2.get("escalation_channels", [])),
                "Reclama√ß√µes Anteriores": "Sim" if analysis2.get("previous_complaints_detected", False) else "N√£o",
                "Indicadores Chave": ", ".join(analysis2.get("key_indicators", [])),
                "Urg√™ncia": analysis2.get("urgency_level", "N/A"),
                
                # Recomenda√ß√µes
                "Recomenda√ß√£o Int‚ÜíExt": analysis1.get("recommendation", "N/A"),
                "Recomenda√ß√£o Repeti√ß√£o": analysis2.get("recommendation", "N/A")
            })
        
        progress_bar.empty()
        status_text.empty()
        
        return pd.DataFrame(results)
        
    except Exception as e:
        st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")
        return None

# Interface principal
st.title("‚ö†Ô∏è An√°lise de Risco de Externaliza√ß√£o de Reclama√ß√µes")
st.markdown("---")

st.markdown("""
### üìä Como funciona:

Esta ferramenta analisa a planilha **"Base Manifesta√ß√µes"** e gera **duas an√°lises de risco** (0-100):

1. **Risco de Internaliza√ß√£o ‚Üí Externaliza√ß√£o**: Probabilidade de reclama√ß√µes internas virarem externas (ReclameAqui, Procon, Ouvidoria)

2. **Risco de Repeti√ß√£o/Escala√ß√£o Externa**: Para reclama√ß√µes j√° externas, qual o risco de o cliente reclamar novamente ou escalar para outros canais

#### Pesos dos Canais (Coluna CANAL_DE_ENTRADA_MANIFESTACAO):
- **Ext. Ouvidoria**: 100 pontos (üî¥ mais cr√≠tico)
- **Externo / Web - Reclame Aqui**: 75 pontos (üü† alto)
- **Externo - Focais**: 50 pontos (üü° m√©dio)
- **Interno**: 0 pontos (üü¢ base para an√°lise)
""")

st.markdown("---")

# Upload de arquivo
uploaded_file = st.file_uploader(
    "üìÅ Fa√ßa upload do Excel do dia (com planilha 'Base Manifesta√ß√µes')",
    type=['xlsx', 'xls'],
    help="Arquivo Excel contendo a planilha 'Base Manifesta√ß√µes' com as reclama√ß√µes"
)

if uploaded_file is not None:
    st.success("‚úÖ Arquivo carregado com sucesso!")
    
    if st.button("üöÄ Iniciar An√°lise", type="primary"):
        with st.spinner("üîç Analisando reclama√ß√µes da planilha 'Base Manifesta√ß√µes'... Isso pode levar alguns minutos."):
            results_df = process_excel_file(uploaded_file, client)
        
        if results_df is not None:
            st.success("‚úÖ An√°lise conclu√≠da!")
            
            # Estat√≠sticas gerais
            st.subheader("üìà Estat√≠sticas Gerais")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                avg_internal_risk = results_df["Risco Interno‚ÜíExterno (0-100)"].mean()
                st.metric("Risco M√©dio Int‚ÜíExt", f"{avg_internal_risk:.1f}/100")
            
            with col2:
                avg_external_risk = results_df["Risco Repeti√ß√£o Externa (0-100)"].mean()
                st.metric("Risco M√©dio Repeti√ß√£o", f"{avg_external_risk:.1f}/100")
            
            with col3:
                critical_internal = len(results_df[results_df["Risco Interno‚ÜíExterno (0-100)"] >= 86])
                st.metric("Casos Cr√≠ticos Int‚ÜíExt", critical_internal)
            
            with col4:
                critical_external = len(results_df[results_df["Risco Repeti√ß√£o Externa (0-100)"] >= 86])
                st.metric("Casos Cr√≠ticos Repeti√ß√£o", critical_external)
            
            # Distribui√ß√£o por canal
            st.subheader("üìä Distribui√ß√£o por Canal")
            col_a, col_b = st.columns(2)
            
            with col_a:
                channel_dist = results_df["Canal Classificado"].value_counts()
                st.bar_chart(channel_dist)
            
            with col_b:
                st.write("**Contagem por Canal:**")
                st.dataframe(channel_dist.reset_index().rename(columns={'index': 'Canal', 'Canal Classificado': 'Quantidade'}))
            
            # Tabela de resultados
            st.subheader("üìã Resultados Detalhados")
            
            # Colorir c√©lulas baseado no risco
            def color_risk(val):
                if isinstance(val, (int, float)):
                    if val >= 86:
                        return 'background-color: #ff4444; color: white'
                    elif val >= 61:
                        return 'background-color: #ff9944; color: white'
                    elif val >= 31:
                        return 'background-color: #ffdd44; color: black'
                    else:
                        return 'background-color: #44ff44; color: black'
                return ''
            
            styled_df = results_df.style.applymap(
                color_risk,
                subset=["Risco Interno‚ÜíExterno (0-100)", "Risco Repeti√ß√£o Externa (0-100)"]
            )
            
            st.dataframe(styled_df, use_container_width=True, height=400)
            
            # Download dos resultados
            st.subheader("üíæ Download dos Resultados")
            
            # Gerar Excel
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"analise_risco_externalizacao_{timestamp}.xlsx"
            
            # Salvar em buffer
            from io import BytesIO
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                results_df.to_excel(writer, index=False, sheet_name='An√°lise de Risco')
            
            st.download_button(
                label="üì• Baixar Resultados (Excel)",
                data=buffer.getvalue(),
                file_name=output_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # Casos priorit√°rios
            st.subheader("üö® Casos Priorit√°rios")
            
            priority_cases = results_df[
                (results_df["Risco Interno‚ÜíExterno (0-100)"] >= 61) | 
                (results_df["Risco Repeti√ß√£o Externa (0-100)"] >= 61)
            ].sort_values(
                by=["Risco Repeti√ß√£o Externa (0-100)", "Risco Interno‚ÜíExterno (0-100)"],
                ascending=False
            )
            
            if len(priority_cases) > 0:
                st.warning(f"‚ö†Ô∏è {len(priority_cases)} casos requerem aten√ß√£o priorit√°ria!")
                st.dataframe(
                    priority_cases[["Linha", "NR_OCORRENCIA", "Canal Classificado", 
                                   "Risco Interno‚ÜíExterno (0-100)", "Risco Repeti√ß√£o Externa (0-100)", 
                                   "Recomenda√ß√£o Int‚ÜíExt", "Recomenda√ß√£o Repeti√ß√£o"]],
                    use_container_width=True
                )
            else:
                st.success("‚úÖ Nenhum caso priorit√°rio identificado!")

else:
    st.info("üëÜ Fa√ßa upload de um arquivo Excel para come√ßar a an√°lise")

# Rodap√©
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9em;'>
    <p>An√°lise de Risco de Externaliza√ß√£o | Powered by OpenAI GPT-4.1-mini</p>
    <p>üìä Planilha analisada: <strong>Base Manifesta√ß√µes</strong></p>
    <p>‚öôÔ∏è Configure a chave da OpenAI em: Settings > Secrets > OPENAI_API_KEY</p>
</div>
""", unsafe_allow_html=True)
